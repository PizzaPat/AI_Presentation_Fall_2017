{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST For Digit Recognizer\n",
    "\n",
    "A lot of the code is adapted from the tensorflow tutorial, MNIST for ML beginners\n",
    "* https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\n",
    "Other References\n",
    "* https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Objects that are intuitive for a human to identify is very hard for a computer such as Pat's computer, Mia, to identify. Examples are digits. It's very easy for us as a human to identify numerical digits 0-9, but the problem comes from the fact that computers only see values as pixels. How is it possible for a computer to identify digits from just RGB pixel values? This project aims to show several ways that we can help a computer identify numerical digits from 0-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The methods we used\n",
    "\n",
    "* Linear classifier using softmax regression\n",
    "* CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries and data set\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "FLAGS = None\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',\n",
    "                      help='Directory for storing input data')\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 55000\n",
      "Number of features (total number of pixels): 784\n",
      "Number of labels: 10\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions for training data\n",
    "x_train = mnist.train.images[:,:]\n",
    "print(\"Number of training examples: \" + str(x_train.shape[0]))\n",
    "print(\"Number of features (total number of pixels): \" + str(x_train.shape[1]))\n",
    "y_train = mnist.train.labels[:,:]\n",
    "print(\"Number of labels: \" + str(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEICAYAAACXj6vjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5b4beaf278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some training data\n",
    "def show_me_a_digit(index):\n",
    "    label = y_train[index].argmax(axis=0)\n",
    "    number = x_train[index].reshape([28,28])\n",
    "    plt.title('Training example #%d   Digit: %d' %(index,label))\n",
    "    plt.imshow(number, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "\n",
    "show_me_a_digit(190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The cost function for our model\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9134\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
